{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST digit recognition",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CDsnJoYQYdgQHsy9YGJ-RIIEVs92CNUS",
      "authorship_tag": "ABX9TyNY1De2xiSRxFD7SH9UJDNM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zeffar/Machine-Learning/blob/main/MNIST_digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXRotAqPKR9a"
      },
      "source": [
        "Please run the following code cells in order :)  (Ctrl+F9 to run all cells)\n",
        "\n",
        "\n",
        "To see the code, double-click a cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_c-maJ-AMZL",
        "cellView": "form"
      },
      "source": [
        "#@title Import Modules and Data\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# improve formatting when ouputting NumPy arrays.\n",
        "np.set_printoptions(linewidth = 200)\n",
        "\n",
        "#import data set\n",
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "#Normalise the Data\n",
        "x_train_normalized = x_train/255\n",
        "x_test_normalized = x_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HfLi-5IBPOh"
      },
      "source": [
        "#@title Define the plotting function { display-mode: \"both\" }\n",
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  for m in list_of_metrics:\n",
        "    x = hist[m]\n",
        "    plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "  plt.legend()\n",
        "  print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtVJRRPNBbck",
        "cellView": "form"
      },
      "source": [
        "#@title Create and train the model\n",
        "#create model class\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Convolution2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_model(my_learning_rate):\n",
        "  model = Sequential()\n",
        "\n",
        "  #turn 28x28 into 784x1 array\n",
        "  model.add(Flatten())\n",
        "\n",
        "  #hidden layers\n",
        "  model.add(Dense(units=256, activation='relu'))\n",
        "  model.add(Dense(units=128, activation='relu'))\n",
        "  \n",
        "  #dropout layer \n",
        "  model.add(Dropout(rate=0.4))\n",
        "\n",
        "  #output layer\n",
        "  model.add(Dense(units=10, activation='softmax'))     \n",
        "\n",
        "  model.compile(optimizer=Adam(lr=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model    \n",
        "\n",
        "\n",
        "#train model class\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.1):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  #checpoint\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint( filepath='savedModelWeighs', period=10, save_weights_only=True )\n",
        "\n",
        "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                      epochs=epochs, callbacks=[model_checkpoint_callback], shuffle=True, \n",
        "                      validation_split=validation_split)\n",
        " \n",
        "  #metrics snapshot at each epoch\n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDW_aRJLCWd5",
        "cellView": "form"
      },
      "source": [
        "#@title Train the model (this takes ~1 minute)\n",
        "#hyperparameters\n",
        "learning_rate = 0.003\n",
        "epochs = 50\n",
        "batch_size = 4000\n",
        "validation_split = 0.2\n",
        "\n",
        "#topography\n",
        "my_model = create_model(learning_rate)\n",
        "\n",
        "#train the model on the set hyperpar.\n",
        "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
        "                           epochs, batch_size, validation_split)\n",
        "\n",
        "#plot metric x epoch\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "\n",
        "#evaluate the model\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xky-PvvqJDWt"
      },
      "source": [
        "The model has an overall accuracy of ~98% over the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKgMnvKxJL45",
        "cellView": "form"
      },
      "source": [
        "#@title Manually test the model: following code outputs the predicted value for the chosen test case, followed by the visualisation of said test case\n",
        "test_value=894 #edit this value\n",
        "plt.imshow(x_test[test_value],cmap='gray', vmin=0, vmax=255)\n",
        "pred=loadedModel.predict(x_test)\n",
        "print(\"predicted value is:\",np.argmax(pred[test_value]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}